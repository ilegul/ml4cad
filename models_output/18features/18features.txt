####################   lr    #########################
Testing on training set:
              precision    recall  f1-score   support

         0.0      0.321     0.709     0.441       505
         1.0      0.949     0.783     0.858      3494

    accuracy                          0.773      3999
   macro avg      0.635     0.746     0.650      3999
weighted avg      0.870     0.773     0.805      3999

auc macro 0.817
confusion matrix
[[ 358  147]
 [ 759 2735]]
Testing on validation set:
              precision    recall  f1-score   support

         0.0      0.314     0.669     0.427       169
         1.0      0.943     0.788     0.858      1165

    accuracy                          0.773      1334
   macro avg      0.628     0.728     0.643      1334
weighted avg      0.863     0.773     0.804      1334

auc macro 0.822
confusion matrix
[[113  56]
 [247 918]]
Model rank: 1
Mean validation score: 0.643 (std: 0.001)
Parameters: {'model__C': 8, 'model__dual': True, 'model__max_iter': 75, 'model__penalty': 'l2', 'model__solver': 'liblinear', 'model__warm_start': False}

####################   lr  END   #########################
####################   svc    #########################
Testing on training set:
              precision    recall  f1-score   support

         0.0      0.348     0.549     0.426       505
         1.0      0.929     0.852     0.889      3494

    accuracy                          0.813      3999
   macro avg      0.639     0.700     0.657      3999
weighted avg      0.856     0.813     0.830      3999

auc macro 0.211
confusion matrix
[[ 277  228]
 [ 518 2976]]
Testing on validation set:
              precision    recall  f1-score   support

         0.0      0.295     0.467     0.362       169
         1.0      0.916     0.838     0.875      1165

    accuracy                          0.791      1334
   macro avg      0.605     0.653     0.618      1334
weighted avg      0.837     0.791     0.810      1334

auc macro 0.275
confusion matrix
[[ 79  90]
 [189 976]]
Model rank: 1
Mean validation score: 0.644 (std: 0.014)
Parameters: {'model__C': 533, 'model__coef0': np.float64(0.7942284005854123), 'model__degree': 111, 'model__gamma': 'auto', 'model__kernel': 'rbf', 'model__max_iter': 1600}

####################   svc  END   #########################
####################   knn    #########################
Testing on training set:
              precision    recall  f1-score   support

         0.0      0.632     0.523     0.572       505
         1.0      0.933     0.956     0.944      3494

    accuracy                          0.901      3999
   macro avg      0.782     0.739     0.758      3999
weighted avg      0.895     0.901     0.897      3999

auc macro 0.926
confusion matrix
[[ 264  241]
 [ 154 3340]]
Testing on validation set:
              precision    recall  f1-score   support

         0.0      0.386     0.290     0.331       169
         1.0      0.901     0.933     0.917      1165

    accuracy                          0.852      1334
   macro avg      0.643     0.611     0.624      1334
weighted avg      0.835     0.852     0.842      1334

auc macro 0.709
confusion matrix
[[  49  120]
 [  78 1087]]
Model rank: 1
Mean validation score: 0.603 (std: 0.017)
Parameters: {'model__algorithm': 'kd_tree', 'model__leaf_size': 49, 'model__n_neighbors': 4, 'model__weights': 'uniform'}

####################   knn  END   #########################
####################   rf    #########################
Testing on training set:
              precision    recall  f1-score   support

         0.0      0.609     0.865     0.715       505
         1.0      0.979     0.920     0.949      3494

    accuracy                          0.913      3999
   macro avg      0.794     0.893     0.832      3999
weighted avg      0.933     0.913     0.919      3999

auc macro 0.967
confusion matrix
[[ 437   68]
 [ 280 3214]]
Testing on validation set:
              precision    recall  f1-score   support

         0.0      0.418     0.544     0.473       169
         1.0      0.931     0.890     0.910      1165

    accuracy                          0.846      1334
   macro avg      0.675     0.717     0.692      1334
weighted avg      0.866     0.846     0.855      1334

auc macro 0.817
confusion matrix
[[  92   77]
 [ 128 1037]]
Model rank: 1
Mean validation score: 0.674 (std: 0.007)
Parameters: {'model__class_weight': 'balanced_subsample', 'model__criterion': 'entropy', 'model__max_features': 'log2', 'model__min_samples_leaf': 4, 'model__min_samples_split': 7, 'model__n_estimators': 86}

####################   rf  END   #########################
####################   adaboost    #########################
Testing on training set:
              precision    recall  f1-score   support

         0.0      0.621     0.162     0.257       505
         1.0      0.891     0.986     0.936      3494

    accuracy                          0.882      3999
   macro avg      0.756     0.574     0.597      3999
weighted avg      0.857     0.882     0.850      3999

auc macro 0.820
confusion matrix
[[  82  423]
 [  50 3444]]
Testing on validation set:
              precision    recall  f1-score   support

         0.0      0.659     0.160     0.257       169
         1.0      0.890     0.988     0.937      1165

    accuracy                          0.883      1334
   macro avg      0.774     0.574     0.597      1334
weighted avg      0.861     0.883     0.850      1334

auc macro 0.811
confusion matrix
[[  27  142]
 [  14 1151]]
Model rank: 1
Mean validation score: 0.608 (std: 0.012)
Parameters: {'model__learning_rate': np.float64(1.0532075221602475), 'model__n_estimators': 87}

####################   adaboost  END   #########################
####################   nn    #########################
Testing on training set:
              precision    recall  f1-score   support

         0.0      0.681     0.279     0.396       505
         1.0      0.904     0.981     0.941      3494

    accuracy                          0.892      3999
   macro avg      0.793     0.630     0.669      3999
weighted avg      0.876     0.892     0.872      3999

auc macro 0.857
confusion matrix
[[ 141  364]
 [  66 3428]]
Testing on validation set:
              precision    recall  f1-score   support

         0.0      0.609     0.249     0.353       169
         1.0      0.900     0.977     0.937      1165

    accuracy                          0.885      1334
   macro avg      0.754     0.613     0.645      1334
weighted avg      0.863     0.885     0.863      1334

auc macro 0.809
confusion matrix
[[  42  127]
 [  27 1138]]
Model rank: 1
Mean validation score: 0.635 (std: 0.004)
Parameters: {'model__alpha': np.float64(0.20331028643001037), 'model__early_stopping': True, 'model__hidden_layer_sizes': [212, 131], 'model__learning_rate': 'adaptive', 'model__learning_rate_init': np.float64(0.0024014202380746256), 'model__max_iter': 430, 'model__solver': 'adam'}

####################   nn  END   #########################
####################   gb    #########################
Testing on training set:
              precision    recall  f1-score   support

         0.0      0.663     0.273     0.387       505
         1.0      0.903     0.980     0.940      3494

    accuracy                          0.891      3999
   macro avg      0.783     0.627     0.664      3999
weighted avg      0.873     0.891     0.870      3999

auc macro 0.848
confusion matrix
[[ 138  367]
 [  70 3424]]
Testing on validation set:
              precision    recall  f1-score   support

         0.0      0.603     0.243     0.346       169
         1.0      0.899     0.977     0.936      1165

    accuracy                          0.884      1334
   macro avg      0.751     0.610     0.641      1334
weighted avg      0.861     0.884     0.861      1334

auc macro 0.807
confusion matrix
[[  41  128]
 [  27 1138]]
Model rank: 1
Mean validation score: 0.640 (std: 0.007)
Parameters: {'model__learning_rate': np.float64(0.1880589330325614), 'model__max_depth': 3, 'model__max_features': None, 'model__n_estimators': 69, 'model__subsample': 0.25}

####################   gb  END   #########################
####################   xgb    #########################
Testing on training set:
              precision    recall  f1-score   support

         0.0      0.456     0.481     0.468       505
         1.0      0.924     0.917     0.921      3494

    accuracy                          0.862      3999
   macro avg      0.690     0.699     0.694      3999
weighted avg      0.865     0.862     0.864      3999

auc macro 0.836
confusion matrix
[[ 243  262]
 [ 290 3204]]
Testing on validation set:
              precision    recall  f1-score   support

         0.0      0.455     0.473     0.464       169
         1.0      0.923     0.918     0.920      1165

    accuracy                          0.861      1334
   macro avg      0.689     0.695     0.692      1334
weighted avg      0.864     0.861     0.863      1334

auc macro 0.824
confusion matrix
[[  80   89]
 [  96 1069]]
Model rank: 1
Mean validation score: 0.679 (std: 0.013)
Parameters: {'model__alpha': np.float64(0.47532827941888217), 'model__booster': 'gbtree', 'model__eta': np.float64(0.13606136854484857), 'model__gamma': np.float64(0.04711874757516637), 'model__lambda': np.float64(0.9655815325635468), 'model__max_depth': 2, 'model__n_estimators': 65, 'model__scale_pos_weight': 0.4, 'model__subsample': 0.5}

####################   xgb  END   #########################
