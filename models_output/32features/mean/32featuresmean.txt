####################   lr    #########################
Testing on training set:
              precision    recall  f1-score   support

         0.0      0.469     0.547     0.505       505
         1.0      0.933     0.911     0.922      3494

    accuracy                          0.865      3999
   macro avg      0.701     0.729     0.713      3999
weighted avg      0.874     0.865     0.869      3999

auc macro 0.854
confusion matrix
[[ 276  229]
 [ 312 3182]]
Testing on validation set:
              precision    recall  f1-score   support

         0.0      0.355     0.462     0.401       143
         1.0      0.926     0.889     0.907      1082

    accuracy                          0.839      1225
   macro avg      0.640     0.675     0.654      1225
weighted avg      0.859     0.839     0.848      1225

auc macro 0.809
confusion matrix
[[ 66  77]
 [120 962]]
Model rank: 1
Mean validation score: 0.707 (std: 0.014)
Parameters: {'model__C': 9, 'model__dual': True, 'model__max_iter': 475, 'model__penalty': 'l2', 'model__solver': 'liblinear', 'model__warm_start': False}

####################   lr  END   #########################
####################   svc    #########################
Testing on training set:
              precision    recall  f1-score   support

         0.0      0.270     0.491     0.348       505
         1.0      0.917     0.808     0.859      3494

    accuracy                          0.768      3999
   macro avg      0.593     0.649     0.603      3999
weighted avg      0.835     0.768     0.794      3999

auc macro 0.279
confusion matrix
[[ 248  257]
 [ 672 2822]]
Testing on validation set:
              precision    recall  f1-score   support

         0.0      0.206     0.392     0.270       143
         1.0      0.909     0.800     0.851      1082

    accuracy                          0.753      1225
   macro avg      0.557     0.596     0.560      1225
weighted avg      0.827     0.753     0.783      1225

auc macro 0.342
confusion matrix
[[ 56  87]
 [216 866]]
Model rank: 1
Mean validation score: 0.674 (std: 0.002)
Parameters: {'model__C': 119, 'model__coef0': np.float64(0.6971844289451361), 'model__degree': 151, 'model__gamma': 'scale', 'model__kernel': 'rbf', 'model__max_iter': 1600}

####################   svc  END   #########################
####################   knn    #########################
Testing on training set:
              precision    recall  f1-score   support

         0.0      0.692     0.552     0.615       505
         1.0      0.937     0.965     0.951      3494

    accuracy                          0.912      3999
   macro avg      0.815     0.758     0.783      3999
weighted avg      0.906     0.912     0.908      3999

auc macro 0.941
confusion matrix
[[ 279  226]
 [ 124 3370]]
Testing on validation set:
              precision    recall  f1-score   support

         0.0      0.333     0.238     0.278       143
         1.0      0.903     0.937     0.920      1082

    accuracy                          0.856      1225
   macro avg      0.618     0.587     0.599      1225
weighted avg      0.836     0.856     0.845      1225

auc macro 0.663
confusion matrix
[[  34  109]
 [  68 1014]]
Model rank: 1
Mean validation score: 0.630 (std: 0.005)
Parameters: {'model__algorithm': 'ball_tree', 'model__leaf_size': 11, 'model__n_neighbors': 4, 'model__weights': 'uniform'}

####################   knn  END   #########################
####################   rf    #########################
Testing on training set:
              precision    recall  f1-score   support

         0.0      0.871     0.966     0.916       505
         1.0      0.995     0.979     0.987      3494

    accuracy                          0.978      3999
   macro avg      0.933     0.973     0.952      3999
weighted avg      0.979     0.978     0.978      3999

auc macro 0.997
confusion matrix
[[ 488   17]
 [  72 3422]]
Testing on validation set:
              precision    recall  f1-score   support

         0.0      0.448     0.329     0.379       143
         1.0      0.914     0.946     0.930      1082

    accuracy                          0.874      1225
   macro avg      0.681     0.638     0.655      1225
weighted avg      0.860     0.874     0.866      1225

auc macro 0.810
confusion matrix
[[  47   96]
 [  58 1024]]
Model rank: 1
Mean validation score: 0.711 (std: 0.001)
Parameters: {'model__class_weight': 'balanced', 'model__criterion': 'entropy', 'model__max_features': 'sqrt', 'model__min_samples_leaf': 4, 'model__min_samples_split': 3, 'model__n_estimators': 124}

####################   rf  END   #########################
####################   adaboost    #########################
Testing on training set:
              precision    recall  f1-score   support

         0.0      0.653     0.283     0.395       505
         1.0      0.904     0.978     0.940      3494

    accuracy                          0.890      3999
   macro avg      0.779     0.631     0.667      3999
weighted avg      0.873     0.890     0.871      3999

auc macro 0.872
confusion matrix
[[ 143  362]
 [  76 3418]]
Testing on validation set:
              precision    recall  f1-score   support

         0.0      0.493     0.245     0.327       143
         1.0      0.906     0.967     0.936      1082

    accuracy                          0.882      1225
   macro avg      0.700     0.606     0.631      1225
weighted avg      0.858     0.882     0.865      1225

auc macro 0.802
confusion matrix
[[  35  108]
 [  36 1046]]
Model rank: 1
Mean validation score: 0.677 (std: 0.005)
Parameters: {'model__learning_rate': np.float64(1.1674688399832753), 'model__n_estimators': 58}

####################   adaboost  END   #########################
####################   nn    #########################
Testing on training set:
              precision    recall  f1-score   support

         0.0      0.598     0.386     0.469       505
         1.0      0.916     0.963     0.938      3494

    accuracy                          0.890      3999
   macro avg      0.757     0.674     0.704      3999
weighted avg      0.876     0.890     0.879      3999

auc macro 0.856
confusion matrix
[[ 195  310]
 [ 131 3363]]
Testing on validation set:
              precision    recall  f1-score   support

         0.0      0.533     0.343     0.417       143
         1.0      0.917     0.960     0.938      1082

    accuracy                          0.888      1225
   macro avg      0.725     0.651     0.678      1225
weighted avg      0.872     0.888     0.877      1225

auc macro 0.814
confusion matrix
[[  49   94]
 [  43 1039]]
Model rank: 1
Mean validation score: 0.706 (std: 0.002)
Parameters: {'model__alpha': np.float64(0.449288214583039), 'model__early_stopping': True, 'model__hidden_layer_sizes': [212, 131], 'model__learning_rate': 'constant', 'model__learning_rate_init': np.float64(0.003126607914163133), 'model__max_iter': 396, 'model__solver': 'adam'}

####################   nn  END   #########################
####################   gb    #########################
Testing on training set:
              precision    recall  f1-score   support

         0.0      0.741     0.386     0.508       505
         1.0      0.917     0.981     0.948      3494

    accuracy                          0.905      3999
   macro avg      0.829     0.683     0.728      3999
weighted avg      0.895     0.905     0.892      3999

auc macro 0.899
confusion matrix
[[ 195  310]
 [  68 3426]]
Testing on validation set:
              precision    recall  f1-score   support

         0.0      0.582     0.273     0.371       143
         1.0      0.910     0.974     0.941      1082

    accuracy                          0.892      1225
   macro avg      0.746     0.623     0.656      1225
weighted avg      0.872     0.892     0.875      1225

auc macro 0.816
confusion matrix
[[  39  104]
 [  28 1054]]
Model rank: 1
Mean validation score: 0.693 (std: 0.006)
Parameters: {'model__learning_rate': np.float64(0.06384160006481765), 'model__max_depth': 3, 'model__max_features': None, 'model__n_estimators': 90, 'model__subsample': 0.25}

####################   gb  END   #########################
####################   xgb    #########################
Testing on training set:
              precision    recall  f1-score   support

         0.0      0.549     0.552     0.551       505
         1.0      0.935     0.934     0.935      3494

    accuracy                          0.886      3999
   macro avg      0.742     0.743     0.743      3999
weighted avg      0.887     0.886     0.886      3999

auc macro 0.879
confusion matrix
[[ 279  226]
 [ 229 3265]]
Testing on validation set:
              precision    recall  f1-score   support

         0.0      0.392     0.434     0.412       143
         1.0      0.924     0.911     0.918      1082

    accuracy                          0.856      1225
   macro avg      0.658     0.672     0.665      1225
weighted avg      0.862     0.856     0.859      1225

auc macro 0.817
confusion matrix
[[ 62  81]
 [ 96 986]]
Model rank: 1
Mean validation score: 0.718 (std: 0.001)
Parameters: {'model__alpha': np.float64(0.07009634744640048), 'model__booster': 'dart', 'model__eta': np.float64(0.2632802717379264), 'model__gamma': np.float64(0.17731500479319856), 'model__lambda': np.float64(1.0713537926603196), 'model__max_depth': 2, 'model__n_estimators': 26, 'model__scale_pos_weight': 0.4, 'model__subsample': 0.5}

####################   xgb  END   #########################
